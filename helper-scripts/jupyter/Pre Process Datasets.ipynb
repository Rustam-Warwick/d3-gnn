{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea79a907-4d81-447a-a81e-a0925d998822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "# import ogb\n",
    "# from ogb.nodeproppred import NodePropPredDataset\n",
    "import collections\n",
    "import os\n",
    "os.environ[\"DATASET_DIR\"] = \"/Users/rustamwarwick/Documents/Projects/d3-gnn/datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c8174-3680-4853-8037-d7d588432902",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tag-Ask-Ubuntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d9bb7a-0271-4931-ab6a-ef71452bfae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagAskUbuntu:\n",
    "    def __init__(self):\n",
    "        n_vertices = pd.read_csv(os.path.join(os.environ[\"DATASET_DIR\"], \"tags-ask-ubuntu\",\"tags-ask-ubuntu-nverts.txt\"), header=None)[0].values\n",
    "        simplices = pd.read_csv(os.path.join(os.environ[\"DATASET_DIR\"], \"tags-ask-ubuntu\",\"tags-ask-ubuntu-simplices.txt\"), header=None)[0].values\n",
    "        n_labels = pd.read_csv(os.path.join(os.environ[\"DATASET_DIR\"], \"tags-ask-ubuntu\",\"tags-ask-ubuntu-node-labels.txt\"), header=None, delimiter=\" \", usecols=[1])[1].values\n",
    "        simplex_labels = pd.read_csv(os.path.join(os.environ[\"DATASET_DIR\"], \"tags-ask-ubuntu\",\"tags-ask-ubuntu-simplex-labels.txt\"), header=None, delimiter=\" \")[0].values\n",
    "        self.q2t = collections.defaultdict(list) # simplex -> [nodes]\n",
    "        self.t2q = collections.defaultdict(list) # nodes -> [simplex]\n",
    "        index = 0\n",
    "        for simplex_idx in range(n_vertices.shape[0]):\n",
    "            s = str(simplex_labels[simplex_idx])\n",
    "            for j in simplices[index:index+n_vertices[simplex_idx]]:\n",
    "                n_label = n_labels[j-1]\n",
    "                self.t2q[n_label].append(s)\n",
    "                self.q2t[s].append(n_label)\n",
    "            index+=n_vertices[simplex_idx]\n",
    "            \n",
    "    def create_files(self):\n",
    "        def create_file(my_dict, destination):\n",
    "            with open(destination,\"w\") as f:\n",
    "                for key, val in my_dict.items():\n",
    "                    f.write(f'{key},{\",\".join(val)}\\n')\n",
    "        create_file(self.q2t, os.path.join(os.environ[\"DATASET_DIR\"], \"tags-ask-ubuntu\",\"tags-ask-ubuntu[question-tag].txt\"))\n",
    "        create_file(self.t2q, os.path.join(os.environ[\"DATASET_DIR\"], \"tags-ask-ubuntu\",\"tags-ask-ubuntu[tag-question].txt\"))\n",
    "        \n",
    "    def generate_statistics(self):\n",
    "        num_nodes = len(self.t2q)\n",
    "        num_hyperedges = len(self.q2t)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c90664-ef88-4cf2-95e1-1ad8e668a5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121.25355857915069, 10.28464271614686)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0unique i,j in res.iterrows():\n",
    "    acc += res[:i][res[:i][0] == j[1]].shape[0]\n",
    "acc = acc / res.shape[0]\n",
    "acc, res.groupby(0).count()[1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43b0bd-7304-4ea8-b533-156ef7066513",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OGB-Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3dd2588-8eaa-4f9d-ae4d-ad88a484c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OGBProducts:\n",
    "    def __init__():\n",
    "        dataset = NodePropPredDataset(name = \"ogbn-products\", root = 'dataset/')\n",
    "        shuffled_topology = pd.DataFrame(dataset.graph['edge_index'].T).sample(frac=1)\n",
    "        features = pd.DataFrame(dataset.graph[\"node_feat\"])\n",
    "        labels = pd.DataFrame(dataset.labels)\n",
    "    def save():\n",
    "        shuffled_topology.to_csv(os.path.join(os.environ[\"DATASET_DIR\"], \"ogb-products\",\"edges.csv\"), header=None, index=False)\n",
    "        features.to_csv(os.path.join(os.environ[\"DATASET_DIR\"], \"ogb-products\",\"node_features.csv\"), header=None)\n",
    "        labels.to_csv(os.path.join(os.environ[\"DATASET_DIR\"], \"ogb-products\",\"node_labels.csv\"), header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a87cc5-ca4f-4087-b958-1660d3c2b75c",
   "metadata": {},
   "source": [
    "## Reddit Hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a7fa820-b785-4a1a-9fe4-8a5a40cd9d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedditHyperlinks:\n",
    "    def __init__(self):\n",
    "            self.dataset_body = pd.read_csv(os.path.join(os.environ[\"DATASET_DIR\"], \"RedditHyperlinks\", \"soc-redditHyperlinks-body.tsv\"), header=None)\n",
    "            self.dataset_title = pd.read_csv(os.path.join(os.environ[\"DATASET_DIR\"], \"RedditHyperlinks\", \"soc-redditHyperlinks-title.tsv\"), header=None)\n",
    "    def save(self):\n",
    "        self.dataset_body.to_csv(os.path.join(os.environ[\"DATASET_DIR\"], \"RedditHyperlinks\", \"soc-redditHyperlinks-body.tsv\"),sep='\\t', index=False, header=False)\n",
    "        self.dataset_title.to_csv(os.path.join(os.environ[\"DATASET_DIR\"], \"RedditHyperlinks\", \"soc-redditHyperlinks-title.tsv\"),sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7adac2ba-88e9-43a0-b2f7-cbed02e717f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rustamwarwick/miniconda3/envs/flink/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3309: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "a = RedditHyperlinks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72912126-a700-4266-9864-47ecfe27f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2d33afd-d8c8-412d-92ad-5f6bfff2d7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_body\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mAnyStr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mna_rep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfloat_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mheader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mline_terminator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdate_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'strict'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Write object to a comma-separated values (csv) file.\n",
       "\n",
       ".. versionchanged:: 0.24.0\n",
       "    The order of arguments for Series was changed.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "path_or_buf : str or file handle, default None\n",
       "    File path or object, if None is provided the result is returned as\n",
       "    a string.  If a file object is passed it should be opened with\n",
       "    `newline=''`, disabling universal newlines.\n",
       "\n",
       "    .. versionchanged:: 0.24.0\n",
       "\n",
       "       Was previously named \"path\" for Series.\n",
       "\n",
       "sep : str, default ','\n",
       "    String of length 1. Field delimiter for the output file.\n",
       "na_rep : str, default ''\n",
       "    Missing data representation.\n",
       "float_format : str, default None\n",
       "    Format string for floating point numbers.\n",
       "columns : sequence, optional\n",
       "    Columns to write.\n",
       "header : bool or list of str, default True\n",
       "    Write out the column names. If a list of strings is given it is\n",
       "    assumed to be aliases for the column names.\n",
       "\n",
       "    .. versionchanged:: 0.24.0\n",
       "\n",
       "       Previously defaulted to False for Series.\n",
       "\n",
       "index : bool, default True\n",
       "    Write row names (index).\n",
       "index_label : str or sequence, or False, default None\n",
       "    Column label for index column(s) if desired. If None is given, and\n",
       "    `header` and `index` are True, then the index names are used. A\n",
       "    sequence should be given if the object uses MultiIndex. If\n",
       "    False do not print fields for index names. Use index_label=False\n",
       "    for easier importing in R.\n",
       "mode : str\n",
       "    Python write mode, default 'w'.\n",
       "encoding : str, optional\n",
       "    A string representing the encoding to use in the output file,\n",
       "    defaults to 'utf-8'.\n",
       "compression : str or dict, default 'infer'\n",
       "    If str, represents compression mode. If dict, value at 'method' is\n",
       "    the compression mode. Compression mode may be any of the following\n",
       "    possible values: {'infer', 'gzip', 'bz2', 'zip', 'xz', None}. If\n",
       "    compression mode is 'infer' and `path_or_buf` is path-like, then\n",
       "    detect compression mode from the following extensions: '.gz',\n",
       "    '.bz2', '.zip' or '.xz'. (otherwise no compression). If dict given\n",
       "    and mode is one of {'zip', 'gzip', 'bz2'}, or inferred as\n",
       "    one of the above, other entries passed as\n",
       "    additional compression options.\n",
       "\n",
       "    .. versionchanged:: 1.0.0\n",
       "\n",
       "       May now be a dict with key 'method' as compression mode\n",
       "       and other entries as additional compression options if\n",
       "       compression mode is 'zip'.\n",
       "\n",
       "    .. versionchanged:: 1.1.0\n",
       "\n",
       "       Passing compression options as keys in dict is\n",
       "       supported for compression modes 'gzip' and 'bz2'\n",
       "       as well as 'zip'.\n",
       "\n",
       "quoting : optional constant from csv module\n",
       "    Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
       "    then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
       "    will treat them as non-numeric.\n",
       "quotechar : str, default '\\\"'\n",
       "    String of length 1. Character used to quote fields.\n",
       "line_terminator : str, optional\n",
       "    The newline character or character sequence to use in the output\n",
       "    file. Defaults to `os.linesep`, which depends on the OS in which\n",
       "    this method is called ('\\n' for linux, '\\r\\n' for Windows, i.e.).\n",
       "\n",
       "    .. versionchanged:: 0.24.0\n",
       "chunksize : int or None\n",
       "    Rows to write at a time.\n",
       "date_format : str, default None\n",
       "    Format string for datetime objects.\n",
       "doublequote : bool, default True\n",
       "    Control quoting of `quotechar` inside a field.\n",
       "escapechar : str, default None\n",
       "    String of length 1. Character used to escape `sep` and `quotechar`\n",
       "    when appropriate.\n",
       "decimal : str, default '.'\n",
       "    Character recognized as decimal separator. E.g. use ',' for\n",
       "    European data.\n",
       "errors : str, default 'strict'\n",
       "    Specifies how encoding and decoding errors are to be handled.\n",
       "    See the errors argument for :func:`open` for a full list\n",
       "    of options.\n",
       "\n",
       "    .. versionadded:: 1.1.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "None or str\n",
       "    If path_or_buf is None, returns the resulting csv format as a\n",
       "    string. Otherwise returns None.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "read_csv : Load a CSV file into a DataFrame.\n",
       "to_excel : Write DataFrame to an Excel file.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
       "...                    'mask': ['red', 'purple'],\n",
       "...                    'weapon': ['sai', 'bo staff']})\n",
       ">>> df.to_csv(index=False)\n",
       "'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
       "\n",
       "Create 'out.zip' containing 'out.csv'\n",
       "\n",
       ">>> compression_opts = dict(method='zip',\n",
       "...                         archive_name='out.csv')  # doctest: +SKIP\n",
       ">>> df.to_csv('out.zip', index=False,\n",
       "...           compression=compression_opts)  # doctest: +SKIP\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/flink/lib/python3.8/site-packages/pandas/core/generic.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a71d86-21fd-41af-8e99-ee77692462af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
