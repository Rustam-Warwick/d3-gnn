{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c702a0-f421-4d55-b833-8e207f91ceeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustambaku13/miniconda3/envs/flink/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.datasets import CoraFull, BitcoinOTC\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4988f99-be7b-4994-84cc-b0a971e2a9bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95997c98-564b-4fa7-8ab8-8ddd967d9733",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CoraFull(\"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e41a4c7f-e85f-4d6d-bdad-b8a9a77cf02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[19793, 8710], edge_index=[2, 126842], y=[19793])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc6a62-5bcf-460a-862e-b7e22fd58f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc102591-6963-41bf-9aaf-1ee964b175b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d065e-995d-4c6d-87eb-f2754724ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ratings = pd.read_csv(\"../datasets/movielens/sorted_ratings.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2967e219-a717-46cc-afec-eb157f24c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = np.unique(np.hstack((sorted_ratings[0].unique(), sorted_ratings[1].unique()))).size\n",
    "x = np.random.normal(size=(num_nodes, 7))\n",
    "edge_index = torch.tensor(np.vstack((sorted_ratings[0].values, sorted_ratings[1].values)))\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "070dbc67-5ec7-4553-9e52-756433fd57ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.num_node_features = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f3013-9631-42c6-a454-58e33c7a8cf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82486e79-38ab-487f-8213-b91267fd7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSage(torch.nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(dataset.num_node_features, 128)\n",
    "        self.conv2 = SAGEConv(128, 64)\n",
    "        self.ff = torch.nn.Sequential(\n",
    "            torch.nn.Linear(64,64),\n",
    "            torch.nn.Linear(64, dataset.num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        if self.training:\n",
    "            x = F.dropout(x, 0.2)\n",
    "        x = self.ff(x)\n",
    "        return F.softmax(x)\n",
    "model = GraphSage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd2725-7283-4161-b233-2c7761d605bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop for 2 layered GCN Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f78c06b4-6cb5-4243-84ff-e8b3f188f581",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-aa6beccaf25d>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2258, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2256, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2228, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2139, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2277, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2206, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2220, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2246, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2247, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2233, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2187, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2174, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2141, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2070, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2085, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1991, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1955, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1825, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1765, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1673, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1590, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1480, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1465, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1447, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1446, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1415, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1374, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1314, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1339, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1327, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1313, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1311, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1245, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1246, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1228, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1192, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1209, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1170, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1134, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1155, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1182, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1363, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1034, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1044, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0957, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0904, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0893, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0808, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0766, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0647, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0555, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0502, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0748, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0515, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0345, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0317, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0126, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9887, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9848, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9782, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9755, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9485, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9506, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9650, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9424, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9418, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9052, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9418, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9735, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8973, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8869, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9024, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8797, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8795, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8820, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8708, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8687, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8697, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8656, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8635, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8642, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8614, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8607, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8620, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8606, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8605, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8605, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8606, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8608, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8591, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8585, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8551, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8566, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8558, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8546, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8640, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9638, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8827, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8884, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8634, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8683, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8652, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8531, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8525, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8540, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8487, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8449, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8439, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8416, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8427, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8398, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8377, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8391, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8382, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8366, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8365, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8361, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8360, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8361, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8361, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8353, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8357, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8355, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8350, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8349, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8345, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8343, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8340, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8337, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8338, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8333, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8329, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8330, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8326, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8323, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8322, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8318, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8317, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8316, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8319, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8312, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8317, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8315, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8313, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8309, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8306, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8310, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8305, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8297, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8287, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8462, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0237, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8693, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0305, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8931, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8799, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8616, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8500, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8591, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8528, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8406, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8384, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8353, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8314, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8283, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8268, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8256, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8233, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8208, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8201, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8199, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8196, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8197, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8189, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8190, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "losses = list()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(dataset[0])\n",
    "    loss = F.cross_entropy(out, dataset[0].y)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a217ebc3-1322-4a7b-8d75-a0c9fb9ead41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9ca2675b50>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0, len(losses) ),losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7f828-0a23-428f-83df-a0cd2ac1cb94",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving model weights for Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9cbcacf-7c15-4d8f-afcc-751be2d231da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_name):\n",
    "    directory = os.path.join(os.path.curdir, \"models/%s-%s/\"%(model_name, datetime.now().date()))\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    i = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        np.save(os.path.join(directory, str(i)), param.data.numpy())\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "754ccade-8d18-4611-aeab-4abfb286e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\"GraphSageBias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "531b0542-7270-4507-b833-b1a735c58695",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\"GraphSage-CoraFull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62ba0929-445b-4418-8530-2656dadc3afc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.lin_l.weight tensor([[ 5.9817e-04, -7.0787e-05, -5.4747e-04,  ..., -3.3149e-04,\n",
      "         -4.4059e-05,  5.0848e-04],\n",
      "        [ 3.6469e-04, -3.0985e-05, -2.0252e-04,  ...,  1.8046e-04,\n",
      "          5.9921e-05, -1.7280e-04],\n",
      "        [ 1.7388e-05, -3.6469e-05, -1.6838e-05,  ..., -8.8189e-07,\n",
      "          5.4335e-05, -1.1658e-05],\n",
      "        ...,\n",
      "        [ 3.5179e-02, -3.3621e-03,  7.1993e-03,  ...,  3.2074e-03,\n",
      "         -1.1755e-02, -2.1390e-02],\n",
      "        [ 1.4919e-03,  8.9092e-05,  1.3309e-04,  ...,  8.8052e-04,\n",
      "         -9.8132e-05,  9.5137e-05],\n",
      "        [ 1.5220e-05, -4.7328e-06,  2.9160e-06,  ..., -3.2813e-06,\n",
      "         -4.0589e-06,  7.9701e-06]])\n",
      "conv1.lin_l.bias tensor([-3.4710e-02, -3.0312e-02, -1.3198e-02, -2.6130e-02,  2.2755e-03,\n",
      "        -2.3397e-04, -1.9671e-03, -1.0809e-02, -3.9789e-02, -4.3510e-03,\n",
      "         1.0627e-02, -1.2442e-04, -3.9706e-02, -1.0531e-02,  4.2310e-02,\n",
      "        -1.5630e-03, -5.3830e-02, -3.5905e-02, -7.4253e-04,  4.9156e-02,\n",
      "         5.2823e-02, -1.5396e-02, -6.5391e-02, -5.2437e-02,  3.8088e-02,\n",
      "        -5.0569e-02, -1.3548e-02, -1.0543e-02, -7.5013e-05,  3.6172e-02,\n",
      "         1.7723e-02, -2.1528e-03, -3.9209e-03, -1.1315e-02,  5.0639e-04,\n",
      "        -1.6770e-02, -2.9858e-03, -4.7349e-03, -1.3951e-03,  2.2192e-02,\n",
      "        -5.2657e-03, -2.4426e-02, -1.6921e-03,  7.1125e-02,  2.7695e-02,\n",
      "        -1.3501e-02,  6.8954e-05, -4.0560e-04, -2.0109e-03, -1.4354e-02,\n",
      "        -9.4209e-03, -9.7495e-05, -4.0636e-02,  6.8227e-02,  1.0097e-01,\n",
      "         2.7823e-02, -1.1771e-02, -1.4801e-02, -3.0057e-02, -3.6385e-02,\n",
      "         8.0324e-02,  3.5400e-03,  6.9967e-02, -1.9603e-02, -1.6906e-02,\n",
      "         6.8712e-02, -2.6199e-02, -6.3403e-05, -5.5788e-03, -1.5230e-03,\n",
      "        -1.1436e-02, -2.0613e-02, -1.8898e-02, -4.1065e-04,  8.6634e-05,\n",
      "        -1.2025e-04, -1.7981e-02, -1.7122e-02, -2.1142e-02, -3.3942e-02,\n",
      "         5.7320e-02, -6.4591e-04, -1.7803e-02, -3.8001e-03, -5.1726e-03,\n",
      "        -5.9350e-02, -2.8976e-02, -1.9775e-02, -9.3964e-03, -1.1616e-04,\n",
      "        -4.1890e-02, -2.9104e-02, -3.4888e-02, -5.8309e-03,  4.5278e-02,\n",
      "        -5.3271e-02,  1.1174e-01,  1.0791e-02, -1.8546e-02,  3.6559e-02,\n",
      "         2.3718e-02, -1.3790e-03, -2.8353e-02, -7.8726e-04, -5.4840e-03,\n",
      "         9.4944e-03, -3.9818e-03, -9.5686e-03,  1.2558e-02, -4.1638e-02,\n",
      "        -6.9226e-03, -6.0422e-04, -2.0630e-05, -1.1785e-04, -2.3793e-02,\n",
      "         3.0666e-02,  6.4788e-03, -2.0998e-02, -3.1175e-02, -8.7187e-03,\n",
      "        -4.0307e-02, -1.8637e-02, -1.5931e-03,  2.1583e-03, -1.3037e-02,\n",
      "         1.2536e-01, -3.2189e-02,  1.5008e-04])\n",
      "conv1.lin_r.weight tensor([[ 3.9620e-05,  2.7789e-04,  4.9637e-04,  ..., -1.2151e-04,\n",
      "         -1.5010e-04,  1.3296e-04],\n",
      "        [-1.8227e-04, -1.0577e-04,  2.0495e-04,  ...,  9.0842e-05,\n",
      "          1.0125e-04, -3.0386e-05],\n",
      "        [ 1.2052e-04, -1.6546e-05,  7.9304e-06,  ..., -5.6519e-05,\n",
      "         -1.5901e-04,  1.3976e-06],\n",
      "        ...,\n",
      "        [ 2.6537e-02, -1.3167e-02,  7.6255e-03,  ...,  8.9313e-03,\n",
      "         -3.4307e-03, -4.0971e-03],\n",
      "        [-3.9193e-04,  1.0629e-04, -7.6564e-05,  ..., -4.7097e-04,\n",
      "         -2.9238e-06, -1.3303e-05],\n",
      "        [ 2.1227e-05, -3.4854e-06, -6.5818e-07,  ..., -9.4799e-06,\n",
      "         -6.7458e-06,  4.8533e-08]])\n",
      "conv2.lin_l.weight tensor([[ 2.1691e-02,  5.3216e-04,  4.2572e-04,  ..., -9.2540e-02,\n",
      "         -3.7739e-03,  1.6652e-03],\n",
      "        [ 4.5762e-02,  1.7833e-02, -3.2825e-04,  ..., -4.9500e-03,\n",
      "          6.2717e-03,  5.2180e-05],\n",
      "        [-5.6846e-02,  2.1011e-03,  1.7226e-03,  ...,  6.3296e-02,\n",
      "         -1.2699e-02,  3.7924e-05],\n",
      "        ...,\n",
      "        [-3.4060e-02,  3.0232e-03,  7.6493e-03,  ...,  1.9026e-01,\n",
      "         -1.2976e-02, -7.2875e-05],\n",
      "        [ 4.5505e-02,  4.3783e-03, -1.3454e-04,  ..., -4.4932e-02,\n",
      "         -4.7737e-04, -1.3252e-03],\n",
      "        [-3.7716e-02,  5.5810e-03, -3.6176e-04,  ..., -4.2748e-02,\n",
      "          4.4509e-03, -3.2222e-04]])\n",
      "conv2.lin_l.bias tensor([ 0.0756,  0.0005,  0.0873,  0.0555,  0.0525,  0.0544, -0.0065,  0.0454,\n",
      "         0.0662,  0.0515,  0.0023,  0.0748,  0.0086,  0.0708,  0.2022,  0.0613,\n",
      "         0.0933,  0.0623,  0.0243,  0.0964,  0.0384,  0.0228,  0.0346,  0.0202,\n",
      "        -0.0015,  0.0129,  0.0655,  0.0084,  0.0584,  0.0064,  0.0649,  0.0278,\n",
      "         0.1901,  0.0140,  0.0590,  0.1641,  0.0085,  0.1528,  0.0523,  0.0904,\n",
      "         0.0657,  0.0869,  0.0126,  0.0608,  0.0275,  0.0726, -0.0149,  0.0311,\n",
      "         0.0699,  0.0622,  0.0902,  0.0570,  0.1465,  0.0731,  0.1225,  0.0525,\n",
      "         0.0716,  0.0076,  0.0077,  0.0292,  0.0902,  0.0795,  0.0454,  0.0771])\n",
      "conv2.lin_r.weight tensor([[ 1.9720e-02,  1.6985e-03,  8.1950e-05,  ..., -2.1460e-01,\n",
      "         -1.0098e-02,  1.3107e-03],\n",
      "        [ 4.8121e-02,  1.7438e-02, -2.2225e-04,  ..., -7.2704e-02,\n",
      "          4.5141e-04,  6.7317e-05],\n",
      "        [-5.7634e-02, -4.7590e-03,  1.7987e-03,  ...,  7.3887e-02,\n",
      "         -1.5687e-02,  3.4768e-05],\n",
      "        ...,\n",
      "        [-3.0317e-02,  4.4048e-03,  7.8961e-03,  ...,  2.8258e-01,\n",
      "         -1.1761e-02, -7.9988e-05],\n",
      "        [ 3.9604e-02,  3.7844e-03, -1.4599e-04,  ..., -1.2019e-01,\n",
      "          4.2560e-03, -1.3779e-03],\n",
      "        [-3.9039e-02,  5.4543e-03, -5.2794e-04,  ..., -4.5083e-02,\n",
      "          5.6959e-03, -3.2504e-04]])\n",
      "ff.0.weight tensor([[ 0.0077, -0.0037, -0.1419,  ...,  0.0349, -0.1623, -0.0085],\n",
      "        [-0.1090, -0.0230, -0.0577,  ..., -0.1207, -0.0141,  0.1622],\n",
      "        [ 0.0474, -0.1777,  0.0538,  ...,  0.0156, -0.0735,  0.1019],\n",
      "        ...,\n",
      "        [ 0.0972, -0.1047,  0.0919,  ...,  0.1373, -0.0513, -0.0505],\n",
      "        [-0.0015,  0.0991, -0.1507,  ...,  0.0140, -0.1334, -0.0596],\n",
      "        [-0.0148, -0.0052, -0.0480,  ..., -0.1381,  0.1188,  0.1568]])\n",
      "ff.0.bias tensor([ 0.0264,  0.0519,  0.0445,  0.0367,  0.0662, -0.0021,  0.0481,  0.0267,\n",
      "        -0.0302,  0.0021,  0.0914,  0.0673, -0.0183, -0.0680, -0.1352,  0.0676,\n",
      "        -0.0216,  0.0039,  0.0354, -0.0092, -0.0003, -0.0650, -0.0444, -0.0494,\n",
      "        -0.0336,  0.0666, -0.0051, -0.0126, -0.0233, -0.0988, -0.0329, -0.0014,\n",
      "         0.0342, -0.0028, -0.0419, -0.0695,  0.0187,  0.2251, -0.0401,  0.0493,\n",
      "        -0.0213, -0.0655, -0.0410,  0.0084,  0.0087, -0.0261, -0.0823,  0.0789,\n",
      "        -0.0169,  0.0470,  0.0115,  0.0659, -0.0164, -0.0442,  0.0580, -0.0699,\n",
      "        -0.1977,  0.0513, -0.0154, -0.0833,  0.0131,  0.0127, -0.0459,  0.0383])\n",
      "ff.1.weight tensor([[ 2.9664e-05, -1.0592e-03, -2.6361e-03,  ..., -1.4791e-03,\n",
      "          5.9332e-04, -1.3093e-03],\n",
      "        [ 2.2148e-04,  1.1338e-03, -4.1831e-04,  ..., -1.1625e-03,\n",
      "          3.8959e-04, -9.2541e-04],\n",
      "        [-2.3129e-03, -7.2119e-04,  2.9984e-03,  ..., -1.5870e-04,\n",
      "         -2.2522e-03, -3.8362e-04],\n",
      "        ...,\n",
      "        [-5.3391e-05, -1.5193e-03, -3.5757e-04,  ..., -2.0127e-04,\n",
      "         -7.1298e-05, -7.8512e-04],\n",
      "        [-2.6104e-04,  2.0736e-03, -2.2526e-04,  ...,  9.2235e-04,\n",
      "         -2.1485e-04, -6.0721e-04],\n",
      "        [-8.2409e-05,  4.1171e-05, -3.3156e-04,  ...,  1.2867e-03,\n",
      "         -1.7484e-04, -5.1794e-04]])\n",
      "ff.1.bias tensor([-1.5782e-02, -2.4700e-03, -1.0436e-02, -2.2948e-03, -8.8993e-04,\n",
      "        -3.5406e-02,  3.5973e-02,  3.1597e-01, -2.5450e-02,  2.1291e-01,\n",
      "        -4.9317e-03,  8.7525e-04,  3.7618e-04,  2.7254e-01,  2.3833e-01,\n",
      "         2.5756e-03,  3.8913e-03,  2.4845e-03,  3.2367e-03,  3.4781e-01,\n",
      "        -4.1506e-03, -2.0376e-03,  9.9615e-02,  5.7934e-04,  7.7615e-03,\n",
      "         5.9723e-04, -8.6070e-04, -1.4505e-01, -6.1401e-03,  7.0088e-02,\n",
      "         1.6546e-03,  1.1920e-03,  1.2777e-03, -1.6488e-01,  1.5722e-01,\n",
      "         1.5184e-03, -1.9072e-03,  4.9932e-04,  1.7203e-03,  8.5709e-03,\n",
      "        -5.4576e-03,  7.7511e-04, -1.1432e-03,  2.7286e-03,  3.4296e-04,\n",
      "         4.1814e-03,  5.9884e-05,  2.4504e-03,  6.3600e-02, -1.7842e-03,\n",
      "         2.5799e-03,  1.8912e-01,  1.9783e-01,  1.5668e-01,  1.7937e-03,\n",
      "        -3.1614e-03,  1.6626e-03,  3.6963e-03, -1.6252e-03,  2.1211e-03,\n",
      "        -5.5258e-03,  2.1987e-03,  2.7048e-03,  1.5026e-04,  1.2622e-03,\n",
      "         1.1563e-03,  1.1382e-03,  2.0643e-03,  2.1673e-03,  2.1075e-03])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "        print(name, param.data\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de30b62-3c3b-48b7-a196-f26a61c63ebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving Graph for Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84aed7e0-9c03-463f-ae76-c07fa99256e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.DataFrame(dataset.data.edge_index.numpy().T)\n",
    "edges.to_csv(\"datasets/cora/edges\", index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "611efe21-7d5a-4480-934a-a3b5a5b630a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertices = pd.DataFrame({\n",
    "\"id\": list(range(0, dataset.data.x.size()[0])),\n",
    "\"feature\": dataset.data.x.numpy().tolist(),\n",
    "\"label\" : dataset.data.y.numpy()\n",
    "}).to_csv(\"datasets/cora/vertices\", index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331470bf-b644-4b75-90fb-59f2ec251349",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame({\n",
    "     \"id\": list(range(0, dataset.data.y.size()[0])),\n",
    "    \"label\": dataset.data.y.numpy() \n",
    "})\n",
    "labels.to_csv(\"datasets/cora/labels\", index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d53dd-2c6d-4af0-bce1-484169023711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
